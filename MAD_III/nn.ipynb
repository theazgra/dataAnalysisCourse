{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# os.chdir(\"MAD_III\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "![title](D:\\\\codes\\\\git\\\\dataAnalysisCourse\\MAD_III\\minimalNN.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv(\"data/iris.csv\",header=None,sep=';')\n",
    "iris = iris.sample(frac=1)\n",
    "iris = iris.sample(frac=1).reset_index(drop=True)\n",
    "# irisInput = [[iris[0][x],iris[1][x],iris[2][x],iris[3][x]] for x in range(len(iris))]\n",
    "# irisGT = [iris[4][x] for x in range(len(iris))]\n",
    "\n",
    "tr = []\n",
    "trGT = []\n",
    "tst = []\n",
    "tstGT = []\n",
    "\n",
    "trainCount = len(iris) * 0.8\n",
    "for x in range(len(iris)):\n",
    "    if x < trainCount:\n",
    "        tr.append([iris[0][x],iris[1][x],iris[2][x],iris[3][x]])\n",
    "        trGT.append(iris[4][x])\n",
    "    else:\n",
    "        tst.append([iris[0][x],iris[1][x],iris[2][x],iris[3][x]])\n",
    "        tstGT.append(iris[4][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nn(trainData, trainGT, testData, testGT, layers,initial_learning_rate, activation_fn='tanh', iters=10000):\n",
    "    nnModel = MLPClassifier(  hidden_layer_sizes=layers,\n",
    "                            learning_rate_init=initial_learning_rate,\n",
    "                            activation=activation_fn,\n",
    "                            solver='adam',\n",
    "                            verbose=False,\n",
    "                            max_iter=iters)\n",
    "    trainedModel = nnModel.fit(trainData, trainGT)\n",
    "    probs = trainedModel.predict_proba(testData)\n",
    "    score = trainedModel.score(testData, testGT)\n",
    "\n",
    "    result = { \"trainingLoss\": round(trainedModel.loss_,5),\n",
    "                \"score\": round(score,5),\n",
    "                # \"predictedProbs\": probs \n",
    "                }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'trainingLoss': 0.04849711888056888, 'score': 1.0, 'testPrecision': 1.0}"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestSolution = test_nn(tr, trGT, tst, tstGT, (3,3),0.05)\n",
    "bestSolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[{'Function': 'identity', 'Training loss': 0.06021, 'Score': 1.0},\n {'Function': 'logistic', 'Training loss': 0.06044, 'Score': 1.0},\n {'Function': 'tanh', 'Training loss': 0.05688, 'Score': 1.0},\n {'Function': 'relu', 'Training loss': 1.1012, 'Score': 0.23333}]"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ACTIVATION FUNCTIONS\n",
    "fns = [\"identity\", \"logistic\", \"tanh\", \"relu\"]\n",
    "fnsResults = []\n",
    "for afn in fns:\n",
    "    fnSolution = test_nn(tr, trGT, tst, tstGT, (3,3),0.05, afn)\n",
    "    fnsResults.append({\"Function\": afn, \"Training loss\": fnSolution[\"trainingLoss\"], \"Score\": fnSolution[\"score\"]})\n",
    "fnsResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[{'Initial learning rate': 1, 'Training loss': 1.10471, 'Score': 0.46667},\n {'Initial learning rate': 0.5, 'Training loss': 1.1171, 'Score': 0.3},\n {'Initial learning rate': 0.25, 'Training loss': 1.09606, 'Score': 0.23333},\n {'Initial learning rate': 0.05, 'Training loss': 0.05671, 'Score': 1.0}]"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INITIAL LEARNING RATES FOR TANH\n",
    "ilrs = [1,0.5,0.25,0.05]\n",
    "ilrsResults = []\n",
    "for ilr in ilrs:\n",
    "    ilrSolution = test_nn(tr, trGT, tst, tstGT, (3,3), ilr, 'tanh',1000)\n",
    "    ilrsResults.append({\"Initial learning rate\": ilr, \"Training loss\": ilrSolution[\"trainingLoss\"], \"Score\": ilrSolution[\"score\"]})\n",
    "ilrsResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[{'Layer neuron count': 1, 'Training loss': 1.09673, 'Score': 0.23333},\n {'Layer neuron count': 2, 'Training loss': 1.09977, 'Score': 0.23333},\n {'Layer neuron count': 4, 'Training loss': 0.05497, 'Score': 1.0},\n {'Layer neuron count': 8, 'Training loss': 0.05492, 'Score': 1.0},\n {'Layer neuron count': 16, 'Training loss': 0.06453, 'Score': 1.0}]"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NUMBER OF NEURONS IN 2 LAYER NETWORK\n",
    "nCounts = [1,2,4,8,16]\n",
    "ncResults = []\n",
    "for nc in nCounts:\n",
    "    ncSolution = test_nn(tr, trGT, tst, tstGT, (nc,nc), 0.05, 'tanh',1000)\n",
    "    ncResults.append({\"Layer neuron count\": nc, \"Training loss\": ncSolution[\"trainingLoss\"], \"Score\": ncSolution[\"score\"]})\n",
    "ncResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(3, 3, 3, 3, 3)"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(5*[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[{'Layer count': 1, 'Training loss': 0.061, 'Score': 1.0},\n {'Layer count': 2, 'Training loss': 0.0605, 'Score': 1.0},\n {'Layer count': 4, 'Training loss': 1.0981, 'Score': 0.3},\n {'Layer count': 6, 'Training loss': 1.10419, 'Score': 0.23333},\n {'Layer count': 8, 'Training loss': 0.48581, 'Score': 0.7},\n {'Layer count': 10, 'Training loss': 1.09813, 'Score': 0.23333},\n {'Layer count': 16, 'Training loss': 1.2583, 'Score': 0.33333}]"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NUMBER OF LAYERS WITH 4 NEURONS IN LAYER\n",
    "lCounts = [1,2,4,6,8,10,16]\n",
    "lcResults = []\n",
    "for lc in lCounts:\n",
    "    lcSolution = test_nn(tr, trGT, tst, tstGT, tuple(lc*[4]), 0.05, 'tanh',1000)\n",
    "    lcResults.append({\"Layer count\": lc, \"Training loss\": lcSolution[\"trainingLoss\"], \"Score\": lcSolution[\"score\"]})\n",
    "lcResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'trainingLoss': 0.18037, 'score': 0.85714}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonSep = pd.read_csv(\"data/nonsep.csv\",header=None,sep=';')\n",
    "nonSep = nonSep.sample(frac=1)\n",
    "nonSep = nonSep.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "nstr = []\n",
    "nstrGT = []\n",
    "nstst = []\n",
    "nststGT = []\n",
    "\n",
    "trainCount = len(nonSep) * 0.8\n",
    "for x in range(len(nonSep)):\n",
    "    if x < trainCount:\n",
    "        nstr.append([nonSep[0][x],nonSep[1][x]])\n",
    "        nstrGT.append(nonSep[2][x])\n",
    "    else:\n",
    "        nstst.append([nonSep[0][x],nonSep[1][x]])\n",
    "        nststGT.append(nonSep[2][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'trainingLoss': 0.27451, 'score': 0.89286}"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nn(nstr, nstrGT, nstst, nststGT, (5,5,1,1), 0.01,'tanh')"
   ]
  }
 ]
}