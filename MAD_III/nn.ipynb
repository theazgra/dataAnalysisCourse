{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# os.chdir(\"MAD_III\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "![title](D:\\\\codes\\\\git\\\\dataAnalysisCourse\\MAD_III\\minimalNN.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv(\"data/iris.csv\",header=None,sep=';')\n",
    "iris = iris.sample(frac=1)\n",
    "iris = iris.sample(frac=1).reset_index(drop=True)\n",
    "# irisInput = [[iris[0][x],iris[1][x],iris[2][x],iris[3][x]] for x in range(len(iris))]\n",
    "# irisGT = [iris[4][x] for x in range(len(iris))]\n",
    "\n",
    "tr = []\n",
    "trGT = []\n",
    "tst = []\n",
    "tstGT = []\n",
    "\n",
    "trainCount = len(iris) * 0.8\n",
    "for x in range(len(iris)):\n",
    "    if x < trainCount:\n",
    "        tr.append([iris[0][x],iris[1][x],iris[2][x],iris[3][x]])\n",
    "        trGT.append(iris[4][x])\n",
    "    else:\n",
    "        tst.append([iris[0][x],iris[1][x],iris[2][x],iris[3][x]])\n",
    "        tstGT.append(iris[4][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nn(trainData, trainGT, testData, testGT, layers,initial_learning_rate, activation_fn='tanh', iters=10000):\n",
    "    nnModel = MLPClassifier(  hidden_layer_sizes=layers,\n",
    "                            learning_rate_init=initial_learning_rate,\n",
    "                            activation=activation_fn,\n",
    "                            solver='adam',\n",
    "                            verbose=False,\n",
    "                            max_iter=iters)\n",
    "    trainedModel = nnModel.fit(trainData, trainGT)\n",
    "    probs = trainedModel.predict_proba(testData)\n",
    "    score = trainedModel.score(testData, testGT)\n",
    "    predictedLabels = trainedModel.predict(testData)\n",
    "    f1 = f1_score(testGT, predictedLabels)\n",
    "\n",
    "    result = { \"trainingLoss\": round(trainedModel.loss_,5),\n",
    "                \"precision\": round(score,5),\n",
    "                \"F1\" : f1\n",
    "                # \"predictedProbs\": probs \n",
    "                }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'trainingLoss': 0.04849711888056888, 'score': 1.0, 'testPrecision': 1.0}"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestSolution = test_nn(tr, trGT, tst, tstGT, (3,3),0.05)\n",
    "bestSolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[{'Function': 'identity', 'Training loss': 0.06021, 'Score': 1.0},\n {'Function': 'logistic', 'Training loss': 0.06044, 'Score': 1.0},\n {'Function': 'tanh', 'Training loss': 0.05688, 'Score': 1.0},\n {'Function': 'relu', 'Training loss': 1.1012, 'Score': 0.23333}]"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ACTIVATION FUNCTIONS\n",
    "fns = [\"identity\", \"logistic\", \"tanh\", \"relu\"]\n",
    "fnsResults = []\n",
    "for afn in fns:\n",
    "    fnSolution = test_nn(tr, trGT, tst, tstGT, (3,3),0.05, afn)\n",
    "    fnsResults.append({\"Function\": afn, \"Training loss\": fnSolution[\"trainingLoss\"], \"Score\": fnSolution[\"precision\"]})\n",
    "fnsResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[{'Initial learning rate': 1, 'Training loss': 1.10471, 'Score': 0.46667},\n {'Initial learning rate': 0.5, 'Training loss': 1.1171, 'Score': 0.3},\n {'Initial learning rate': 0.25, 'Training loss': 1.09606, 'Score': 0.23333},\n {'Initial learning rate': 0.05, 'Training loss': 0.05671, 'Score': 1.0}]"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INITIAL LEARNING RATES FOR TANH\n",
    "ilrs = [1,0.5,0.25,0.05]\n",
    "ilrsResults = []\n",
    "for ilr in ilrs:\n",
    "    ilrSolution = test_nn(tr, trGT, tst, tstGT, (3,3), ilr, 'tanh',1000)\n",
    "    ilrsResults.append({\"Initial learning rate\": ilr, \"Training loss\": ilrSolution[\"trainingLoss\"], \"Score\": ilrSolution[\"precision\"]})\n",
    "ilrsResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[{'Layer neuron count': 1, 'Training loss': 1.09673, 'Score': 0.23333},\n {'Layer neuron count': 2, 'Training loss': 1.09977, 'Score': 0.23333},\n {'Layer neuron count': 4, 'Training loss': 0.05497, 'Score': 1.0},\n {'Layer neuron count': 8, 'Training loss': 0.05492, 'Score': 1.0},\n {'Layer neuron count': 16, 'Training loss': 0.06453, 'Score': 1.0}]"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NUMBER OF NEURONS IN 2 LAYER NETWORK\n",
    "nCounts = [1,2,4,8,16]\n",
    "ncResults = []\n",
    "for nc in nCounts:\n",
    "    ncSolution = test_nn(tr, trGT, tst, tstGT, (nc,nc), 0.05, 'tanh',1000)\n",
    "    ncResults.append({\"Layer neuron count\": nc, \"Training loss\": ncSolution[\"trainingLoss\"], \"Score\": ncSolution[\"precision\"]})\n",
    "ncResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(3, 3, 3, 3, 3)"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(5*[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[{'Layer count': 1, 'Training loss': 0.061, 'Score': 1.0},\n {'Layer count': 2, 'Training loss': 0.0605, 'Score': 1.0},\n {'Layer count': 4, 'Training loss': 1.0981, 'Score': 0.3},\n {'Layer count': 6, 'Training loss': 1.10419, 'Score': 0.23333},\n {'Layer count': 8, 'Training loss': 0.48581, 'Score': 0.7},\n {'Layer count': 10, 'Training loss': 1.09813, 'Score': 0.23333},\n {'Layer count': 16, 'Training loss': 1.2583, 'Score': 0.33333}]"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NUMBER OF LAYERS WITH 4 NEURONS IN LAYER\n",
    "lCounts = [1,2,4,6,8,10,16]\n",
    "lcResults = []\n",
    "for lc in lCounts:\n",
    "    lcSolution = test_nn(tr, trGT, tst, tstGT, tuple(lc*[4]), 0.05, 'tanh',1000)\n",
    "    lcResults.append({\"Layer count\": lc, \"Training loss\": lcSolution[\"trainingLoss\"], \"Score\": lcSolution[\"precision\"]})\n",
    "lcResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonSep = pd.read_csv(\"data/nonsep.csv\",header=None,sep=';')\n",
    "nonSep = nonSep.sample(frac=1)\n",
    "nonSep = nonSep.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "nonSepTrain = []\n",
    "nonSepTrainGT = []\n",
    "nonSepTest = []\n",
    "nonSepTestGT = []\n",
    "\n",
    "trainCount = len(nonSep) * 0.8\n",
    "for x in range(len(nonSep)):\n",
    "    if x < trainCount:\n",
    "        nonSepTrain.append([nonSep[0][x],nonSep[1][x]])\n",
    "        nonSepTrainGT.append(nonSep[2][x])\n",
    "    else:\n",
    "        nonSepTest.append([nonSep[0][x],nonSep[1][x]])\n",
    "        nonSepTestGT.append(nonSep[2][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'trainingLoss': 0.29291, 'precision': 0.92857, 'F1 score': 0.9230769230769231}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nn(nonSepTrain, nonSepTrainGT, nonSepTest, nonSepTestGT, (5,5,1,1), 0.01,'tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Layers (4,)\n1 layers with 4 neurons, train loss: 0.24971 precision: 0.92857 F1 score: 0.9230769230769231\nLayers (4, 4)\n2 layers with 4 neurons, train loss: 0.25704 precision: 0.92857 F1 score: 0.9230769230769231\nLayers (4, 4, 4)\n3 layers with 4 neurons, train loss: 0.25277 precision: 0.92857 F1 score: 0.9230769230769231\nLayers (4, 4, 4, 4)\n4 layers with 4 neurons, train loss: 0.12485 precision: 0.92857 F1 score: 0.9230769230769231\nLayers (4, 4, 4, 4, 4)\n5 layers with 4 neurons, train loss: 0.18329 precision: 0.92857 F1 score: 0.9230769230769231\nLayers (4, 4, 4, 4, 4, 4)\n6 layers with 4 neurons, train loss: 0.28809 precision: 0.92857 F1 score: 0.9230769230769231\nLayers (4, 4, 4, 4, 4, 4, 4)\n7 layers with 4 neurons, train loss: 0.2254 precision: 0.92857 F1 score: 0.9230769230769231\nLayers (4, 4, 4, 4, 4, 4, 4, 4)\n8 layers with 4 neurons, train loss: 0.68908 precision: 0.53571 F1 score: 0.0\nLayers (4, 4, 4, 4, 4, 4, 4, 4, 4)\n9 layers with 4 neurons, train loss: 0.28721 precision: 0.92857 F1 score: 0.9230769230769231\nC:\\Users\\theaz\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\nLayers (4, 4, 4, 4, 4, 4, 4, 4, 4, 4)\n10 layers with 4 neurons, train loss: 0.35937 precision: 0.85714 F1 score: 0.8181818181818181\nLayers (4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)\n11 layers with 4 neurons, train loss: 0.23771 precision: 0.92857 F1 score: 0.9230769230769231\nLayers (4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)\n12 layers with 4 neurons, train loss: 0.28653 precision: 0.92857 F1 score: 0.9230769230769231\n"
    }
   ],
   "source": [
    "neuronCount = 4\n",
    "for layerCount in range(1,13):\n",
    "    solution = test_nn(nonSepTrain, nonSepTrainGT, nonSepTest, nonSepTestGT, tuple(layerCount*[neuronCount]), 0.01,'tanh')\n",
    "    print(f\"Layers {tuple(layerCount*[neuronCount])}\")\n",
    "    print(f\"{layerCount} layers with 4 neurons, train loss: {solution['trainingLoss']} precision: {solution['precision']} F1 score: {solution['F1']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Layers (2,)\n1 layers with 4 neurons, train loss: 0.26473 precision: 0.92857 F1 score: 0.9230769230769231\nLayers (2, 2)\n2 layers with 4 neurons, train loss: 0.27832 precision: 0.92857 F1 score: 0.9230769230769231\nLayers (2, 2, 2)\n3 layers with 4 neurons, train loss: 0.69271 precision: 0.46429 F1 score: 0.6341463414634146\nLayers (2, 2, 2, 2)\n4 layers with 4 neurons, train loss: 0.26789 precision: 0.92857 F1 score: 0.9230769230769231\nLayers (2, 2, 2, 2, 2)\n5 layers with 4 neurons, train loss: 0.22728 precision: 0.92857 F1 score: 0.9230769230769231\nC:\\Users\\theaz\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\nLayers (2, 2, 2, 2, 2, 2)\n6 layers with 4 neurons, train loss: 0.69301 precision: 0.53571 F1 score: 0.0\nLayers (2, 2, 2, 2, 2, 2, 2)\n7 layers with 4 neurons, train loss: 0.69311 precision: 0.46429 F1 score: 0.6341463414634146\nLayers (2, 2, 2, 2, 2, 2, 2, 2)\n8 layers with 4 neurons, train loss: 0.22487 precision: 0.92857 F1 score: 0.9230769230769231\nLayers (2, 2, 2, 2, 2, 2, 2, 2, 2)\n9 layers with 4 neurons, train loss: 0.69293 precision: 0.46429 F1 score: 0.6341463414634146\nLayers (2, 2, 2, 2, 2, 2, 2, 2, 2, 2)\n10 layers with 4 neurons, train loss: 0.69302 precision: 0.46429 F1 score: 0.6341463414634146\nLayers (2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)\n11 layers with 4 neurons, train loss: 0.69388 precision: 0.46429 F1 score: 0.6341463414634146\nLayers (2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)\n12 layers with 4 neurons, train loss: 0.693 precision: 0.46429 F1 score: 0.6341463414634146\n"
    }
   ],
   "source": [
    "neuronCount = 2\n",
    "for layerCount in range(1,13):\n",
    "    solution = test_nn(nonSepTrain, nonSepTrainGT, nonSepTest, nonSepTestGT, tuple(layerCount*[neuronCount]), 0.01,'tanh')\n",
    "    print(f\"Layers {tuple(layerCount*[neuronCount])}\")\n",
    "    print(f\"{layerCount} layers with 4 neurons, train loss: {solution['trainingLoss']} precision: {solution['precision']} F1 score: {solution['F1']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Layers (10,)\n1 layers with 4 neurons, train loss: 0.24818 precision: 0.92857 F1 score: 0.9230769230769231\nLayers (10, 10)\n2 layers with 4 neurons, train loss: 0.24738 precision: 0.92857 F1 score: 0.9230769230769231\nLayers (10, 10, 10)\n3 layers with 4 neurons, train loss: 0.07897 precision: 0.92857 F1 score: 0.9230769230769231\nLayers (10, 10, 10, 10)\n4 layers with 4 neurons, train loss: 0.16671 precision: 0.92857 F1 score: 0.9230769230769231\nLayers (10, 10, 10, 10, 10)\n5 layers with 4 neurons, train loss: 0.14131 precision: 0.89286 F1 score: 0.888888888888889\nLayers (10, 10, 10, 10, 10, 10)\n6 layers with 4 neurons, train loss: 0.28349 precision: 0.92857 F1 score: 0.9230769230769231\nLayers (10, 10, 10, 10, 10, 10, 10)\n7 layers with 4 neurons, train loss: 0.28958 precision: 0.92857 F1 score: 0.9230769230769231\nLayers (10, 10, 10, 10, 10, 10, 10, 10)\n8 layers with 4 neurons, train loss: 0.2868 precision: 0.92857 F1 score: 0.9230769230769231\nLayers (10, 10, 10, 10, 10, 10, 10, 10, 10)\n9 layers with 4 neurons, train loss: 0.23272 precision: 0.92857 F1 score: 0.9230769230769231\nLayers (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)\n10 layers with 4 neurons, train loss: 0.32056 precision: 0.92857 F1 score: 0.9230769230769231\nLayers (10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10)\n11 layers with 4 neurons, train loss: 0.23565 precision: 0.85714 F1 score: 0.8181818181818181\nLayers (10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10)\n12 layers with 4 neurons, train loss: 0.3033 precision: 0.92857 F1 score: 0.9230769230769231\n"
    }
   ],
   "source": [
    "neuronCount = 10\n",
    "for layerCount in range(1,13):\n",
    "    solution = test_nn(nonSepTrain, nonSepTrainGT, nonSepTest, nonSepTestGT, tuple(layerCount*[neuronCount]), 0.01,'tanh')\n",
    "    print(f\"Layers {tuple(layerCount*[neuronCount])}\")\n",
    "    print(f\"{layerCount} layers with 4 neurons, train loss: {solution['trainingLoss']} precision: {solution['precision']} F1 score: {solution['F1']}\")"
   ]
  }
 ]
}