{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from timeit import default_timer as timer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sklearn.feature_selection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/real_data_classification_X.csv', index_col=0)\n",
    "gt = pd.read_csv('data/real_data_classification_y.csv', index_col=0)\n",
    "gt=gt['0'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNormStandard = df\n",
    "dfNormMinMax = df\n",
    "scalerStandard = StandardScaler()\n",
    "scalerMinMax = MinMaxScaler()\n",
    "# Normaliza also categorial data\n",
    "for col in df.columns:\n",
    "    scaledValuesStand = scalerStandard.fit_transform(df[col].values.reshape(-1,1))\n",
    "    scaledValuesMinMax = scalerMinMax.fit_transform(df[col].values.reshape(-1,1))\n",
    "    dfNormStandard[col] = scaledValuesStand\n",
    "    dfNormMinMax[col] = scaledValuesMinMax\n",
    "    \n",
    "dfNormStandard.shape == dfNormMinMax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "StandardScaler(copy=True, with_mean=True, with_std=True)"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalerStandard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNormStandard= PCA(n_components=15).fit_transform(dfNormStandard)\n",
    "dfNormMinMax= PCA(n_components=15).fit_transform(dfNormMinMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_test(classifierName,datasetName,dataset, labels, classifier, k=3, shuffleDataset=True):\n",
    "    kFold = KFold(n_splits=k, shuffle=shuffleDataset)\n",
    "    kFoldResult = []\n",
    "    kFoldIndex = 0\n",
    "    for train_index, test_index in kFold.split(dataset):\n",
    "        X_train = dataset[train_index]\n",
    "        X_test = dataset[test_index]\n",
    "        # X_train, X_test = dataset[train_index], dataset[test_index]\n",
    "        Y_train = labels[train_index]\n",
    "        Y_test = labels[test_index]\n",
    "        print(X_train.shape)\n",
    "        # print()\n",
    "        # Y_train, Y_test = labels[train_index], labels[test_index]\n",
    "        start = timer()\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        fitTime = timer() - start\n",
    "        \n",
    "        start = timer()\n",
    "        predictedLabels = classifier.predict(X_test)\n",
    "        predictionTime = timer() - start\n",
    "\n",
    "        predictionProbs = classifier.predict_proba(X_test)\n",
    "        rocAucScore = roc_auc_score(Y_test, predictionProbs[:,1])\n",
    "        \n",
    "        score = float(sum([p[0] == p[1] for p in zip(predictedLabels, Y_test)])) / float(len(Y_test))\n",
    "        f1Score = f1_score(Y_test, predictedLabels)\n",
    "\n",
    "        kFoldResult.append({\n",
    "            \"Dataset\": datasetName,\n",
    "            \"Classifier\": classifierName,\n",
    "            \"KFoldIndex\": kFoldIndex,\n",
    "            \"FitTime\": fitTime,\n",
    "            \"PredictionTime\": predictionTime,\n",
    "            \"Precision\": score,\n",
    "            \"F1Score\": f1Score,\n",
    "            \"RocAucScore\": rocAucScore\n",
    "          })\n",
    "        kFoldIndex += 1\n",
    "    print(f\"Finished classification for {classifierName}-{datasetName}\")\n",
    "    return kFoldResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(5000, 15)\n(5000, 15)\nFinished classification for DecTree-NormStandard\n"
    }
   ],
   "source": [
    "\n",
    "decisionTreeClassifier = DecisionTreeClassifier(min_samples_leaf=80)\n",
    "# results += k_fold_test(\"DecTree\",\"NormMinMax\",dfNormMinMax,gt,decisionTreeClassifier,2,False)\n",
    "results += k_fold_test(\"DecTree\",\"NormStandard\",dfNormStandard,gt,decisionTreeClassifier,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "C:\\Users\\theaz\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\nFinished classification for MLPC-NormStandard\nC:\\Users\\theaz\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
    }
   ],
   "source": [
    "nnClassifier = MLPClassifier(hidden_layer_sizes=(5,5))\n",
    "# results += k_fold_test(\"MLPC\",\"NormMinMax\",dfNormMinMax,gt,nnClassifier,2,False)\n",
    "results += k_fold_test(\"MLPC\",\"NormStandard\",dfNormStandard,gt,nnClassifier,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "C:\\Users\\theaz\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\nC:\\Users\\theaz\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:241: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  % self.max_iter, ConvergenceWarning)\nC:\\Users\\theaz\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\nFinished classification for SVM-NormStandard\nC:\\Users\\theaz\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:241: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n  % self.max_iter, ConvergenceWarning)\n"
    }
   ],
   "source": [
    "svmClassifier = SVC(C=1000, max_iter=2000, probability=True)\n",
    "# results += k_fold_test(\"SVM\",\"NormMinMax\",dfNormMinMax,gt,svmClassifier,2,False)\n",
    "results += k_fold_test(\"SVM\",\"NormStandard\",dfNormStandard,gt,svmClassifier,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Classifier</th>\n      <th>Dataset</th>\n      <th>F1Score</th>\n      <th>FitTime</th>\n      <th>KFoldIndex</th>\n      <th>Precision</th>\n      <th>PredictionTime</th>\n      <th>RocAucScore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>SVM</td>\n      <td>NormStandard</td>\n      <td>0.952663</td>\n      <td>0.966659</td>\n      <td>1</td>\n      <td>0.9328</td>\n      <td>0.091120</td>\n      <td>0.968215</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SVM</td>\n      <td>NormStandard</td>\n      <td>0.950986</td>\n      <td>0.995484</td>\n      <td>0</td>\n      <td>0.9304</td>\n      <td>0.090026</td>\n      <td>0.899407</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MLPC</td>\n      <td>NormStandard</td>\n      <td>0.949730</td>\n      <td>1.567295</td>\n      <td>0</td>\n      <td>0.9292</td>\n      <td>0.001037</td>\n      <td>0.974033</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>DecTree</td>\n      <td>NormStandard</td>\n      <td>0.947804</td>\n      <td>0.042158</td>\n      <td>1</td>\n      <td>0.9268</td>\n      <td>0.000582</td>\n      <td>0.972905</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MLPC</td>\n      <td>NormStandard</td>\n      <td>0.947052</td>\n      <td>1.735883</td>\n      <td>1</td>\n      <td>0.9260</td>\n      <td>0.000885</td>\n      <td>0.972375</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>DecTree</td>\n      <td>NormStandard</td>\n      <td>0.942624</td>\n      <td>0.048246</td>\n      <td>0</td>\n      <td>0.9198</td>\n      <td>0.000946</td>\n      <td>0.971039</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "  Classifier       Dataset   F1Score   FitTime  KFoldIndex  Precision  \\\n5        SVM  NormStandard  0.952663  0.966659           1     0.9328   \n4        SVM  NormStandard  0.950986  0.995484           0     0.9304   \n2       MLPC  NormStandard  0.949730  1.567295           0     0.9292   \n1    DecTree  NormStandard  0.947804  0.042158           1     0.9268   \n3       MLPC  NormStandard  0.947052  1.735883           1     0.9260   \n0    DecTree  NormStandard  0.942624  0.048246           0     0.9198   \n\n   PredictionTime  RocAucScore  \n5        0.091120     0.968215  \n4        0.090026     0.899407  \n2        0.001037     0.974033  \n1        0.000582     0.972905  \n3        0.000885     0.972375  \n0        0.000946     0.971039  "
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsDf = pd.DataFrame(results)\n",
    "resultsDf.sort_values(by=['F1Score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "C:\\Users\\theaz\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n  warnings.warn(CV_WARNING, FutureWarning)\nC:\\Users\\theaz\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\nC:\\Users\\theaz\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
    },
    {
     "data": {
      "text/plain": "array([0.9280144 , 0.92979298, 0.9279928 ])"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(nnClassifier, dfNormStandard, gt)\n",
    "\n",
    "# kFold = KFold(n_splits=2, shuffle=True)\n",
    "# X_tr=[]\n",
    "# X_te=[]\n",
    "# Y_tr=[]\n",
    "# Y_te=[]\n",
    "# for train_index, test_index in kFold.split(dfNormStandard):\n",
    "#     X_tr, X_te = dfNormStandard[train_index], dfNormStandard[test_index]\n",
    "#     Y_tr, Y_te = gt[train_index], gt[test_index]\n",
    "    \n",
    "#     print(X_tr)\n",
    "#     print(X_te)\n",
    "#     nnClassifier.fit(X_tr, Y_tr)\n",
    "#     print(nnClassifier.score(X_te, Y_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Classifier: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n                       max_features=None, max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=80, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, presort=False,\n                       random_state=None, splitter='best') score: 0.9172\nClassifier: MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n              hidden_layer_sizes=(5, 5), learning_rate='constant',\n              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n              validation_fraction=0.1, verbose=False, warm_start=False) score: 0.9308\nClassifier: SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n    kernel='rbf', max_iter=2000, probability=True, random_state=None,\n    shrinking=True, tol=0.001, verbose=False) score: 0.9288\n"
    }
   ],
   "source": [
    "classifiers = [decisionTreeClassifier, nnClassifier, svmClassifier]\n",
    "for classifier in classifiers:\n",
    "    bagginClassifier = BaggingClassifier(base_estimator=classifier, n_jobs=6, n_estimators=20)\n",
    "    bagginClassifier.fit(X_tr, Y_tr)\n",
    "    print(f\"Classifier: {classifier} score: {bagginClassifier.score(X_te,Y_te)}\")\n",
    "    # bagginClassifier.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "C:\\Users\\theaz\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\nFinished classification for RandomForest-DfNumStand\n"
    },
    {
     "data": {
      "text/plain": "[{'Dataset': 'DfNumStand',\n  'Classifier': 'RandomForest',\n  'KFoldIndex': 0,\n  'FitTime': 0.06873220000034053,\n  'PredictionTime': 0.0058328999998593645,\n  'Precision': 0.93,\n  'F1Score': 0.9491279069767442,\n  'RocAucScore': 0.973139791128774},\n {'Dataset': 'DfNumStand',\n  'Classifier': 'RandomForest',\n  'KFoldIndex': 1,\n  'FitTime': 0.07011600000032558,\n  'PredictionTime': 0.004960199999914039,\n  'Precision': 0.9236,\n  'F1Score': 0.9442009932807479,\n  'RocAucScore': 0.9701736710654588}]"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomForest = RandomForestClassifier()\n",
    "randomForest.fit(X_tr,Y_tr)\n",
    "randomForest.score(X_te,Y_te)\n",
    "k_fold_test(\"RandomForest\",\"DfNumStand\",dfNormStandard,gt,randomForest,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Finished classification for AdaBoostDecTree-NormStandard\n"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Classifier</th>\n      <th>Dataset</th>\n      <th>F1Score</th>\n      <th>FitTime</th>\n      <th>KFoldIndex</th>\n      <th>Precision</th>\n      <th>PredictionTime</th>\n      <th>RocAucScore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>AdaBoostDecTree</td>\n      <td>NormStandard</td>\n      <td>0.947322</td>\n      <td>3.821253</td>\n      <td>1</td>\n      <td>0.9276</td>\n      <td>0.065747</td>\n      <td>0.975510</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>AdaBoostDecTree</td>\n      <td>NormStandard</td>\n      <td>0.947292</td>\n      <td>3.819608</td>\n      <td>0</td>\n      <td>0.9270</td>\n      <td>0.065348</td>\n      <td>0.974852</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "        Classifier       Dataset   F1Score   FitTime  KFoldIndex  Precision  \\\n1  AdaBoostDecTree  NormStandard  0.947322  3.821253           1     0.9276   \n0  AdaBoostDecTree  NormStandard  0.947292  3.819608           0     0.9270   \n\n   PredictionTime  RocAucScore  \n1        0.065747     0.975510  \n0        0.065348     0.974852  "
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaBoostClf = AdaBoostClassifier(base_estimator=decisionTreeClassifier,n_estimators=100)\n",
    "ada = k_fold_test(\"AdaBoostDecTree\",\"NormStandard\",dfNormStandard,gt,adaBoostClf,2,False)\n",
    "resultsDf2 = pd.DataFrame(ada)\n",
    "resultsDf2.sort_values(by=['F1Score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Finished classification for AdaBoostDecTree-NormStandard\n"
    },
    {
     "data": {
      "text/plain": "[{'Dataset': 'NormStandard',\n  'Classifier': 'AdaBoostDecTree',\n  'KFoldIndex': 0,\n  'FitTime': 2.13050770000018,\n  'PredictionTime': 0.0016116000001602515,\n  'Precision': 0.9298,\n  'F1Score': 0.9504167255262044,\n  'RocAucScore': 0.9780806927028718},\n {'Dataset': 'NormStandard',\n  'Classifier': 'AdaBoostDecTree',\n  'KFoldIndex': 1,\n  'FitTime': 2.0395406000002367,\n  'PredictionTime': 0.0016670999998495972,\n  'Precision': 0.9298,\n  'F1Score': 0.9498213009292352,\n  'RocAucScore': 0.9775288075644977}]"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "votingClass = VotingClassifier(estimators=[('DecTree', decisionTreeClassifier), ('MPLC', nnClassifier)], n_jobs=6,voting='soft')\n",
    "k_fold_test(\"AdaBoostDecTree\",\"NormStandard\",dfNormStandard,gt,votingClass,2,False)"
   ]
  }
 ]
}